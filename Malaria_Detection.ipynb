{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM9ZX7njJduhlDkZ4Ske0Sf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntonisGantzos/Tensorflow-ML_Projects/blob/main/Malaria_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Malaria detection using Tensorflow\n",
        "The aim of this project is to utilize the TensorFlow framework, in order to create, train, validate and subsequently deploy a Convoluted Neural Network (CNN) model that is given an image of a patient's blood sample and is able to predict wether the patient suffers from Malaria or not."
      ],
      "metadata": {
        "id": "gwVnfqWkQJK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-datasets tensorflow"
      ],
      "metadata": {
        "id": "TX-CyklfRl4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "print(f\"Tensorflow is using version : {tf.__version__}\")\n"
      ],
      "metadata": {
        "id": "g7s6NQ4dRnDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0de6c4-ba76-4e1f-af15-29438421368f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow is using version : 2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset and info about it\n",
        "dataset, dataset_info = tfds.load('malaria', with_info=True, as_supervised=True, shuffle_files=True, split=['train'])"
      ],
      "metadata": {
        "id": "mx5pBg8wSGG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can see that dataset is a list that consists of 2 elemens\n",
        "#the iterable dataset is the first element on this list that we get as output\n",
        "dataset, dataset[0]"
      ],
      "metadata": {
        "id": "a2gYDW5je1wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_info"
      ],
      "metadata": {
        "id": "Xj8_b1mmTD1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set train, validation and test splits\n",
        "TRAIN_RATIO = 0.8\n",
        "TEST_RATIO = 0.1\n",
        "VALIDATION_RATIO = 0.1\n",
        "#dataset = tf.data.Dataset.range(10)\n",
        "\n",
        "print(f\"Train ratio : {TRAIN_RATIO}\")\n",
        "print(f\"Test ratio : {TEST_RATIO}\")\n",
        "print(f\"Validation ratio : {VALIDATION_RATIO}\")"
      ],
      "metadata": {
        "id": "5_Evw9efVm1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a function to automate data split\n",
        "def splits(dataset, TRAIN_RATIO, VALIDATION_RATIO, TEST_RATIO):\n",
        "  #keep the first 10 elements of the total dataset\n",
        "  print(f\"complete dataset : {list(dataset.as_numpy_iterator())}\")\n",
        "  DATASET_SIZE = len(dataset)\n",
        "  print(f\"dataset size : {DATASET_SIZE}\")\n",
        "\n",
        "  #set the train validation and test dataset\n",
        "  train_dataset = dataset.take(int(TRAIN_RATIO * DATASET_SIZE))\n",
        "  print(f\"train_dataset : {list(train_dataset.take(1).as_numpy_iterator())}\")\n",
        "\n",
        "  val_dataset = dataset.skip(int(TRAIN_RATIO * DATASET_SIZE)).take(int(VALIDATION_RATIO * DATASET_SIZE))\n",
        "  print(f\"validation dataset : {list(val_dataset.take(1).as_numpy_iterator())}\")\n",
        "\n",
        "  test_dataset = dataset.skip(int(TRAIN_RATIO * DATASET_SIZE) + int(VALIDATION_RATIO * DATASET_SIZE))\n",
        "  print(f\"test dataset : {list(test_dataset.take(1).as_numpy_iterator())}\")\n",
        "\n",
        "  return train_dataset, val_dataset, test_dataset"
      ],
      "metadata": {
        "id": "IXlInMffqMvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset, test_dataset = splits(dataset[0].take(1500), TRAIN_RATIO, VALIDATION_RATIO, TEST_RATIO)"
      ],
      "metadata": {
        "id": "IKxT9otRsyBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "nlk1onohHns5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (image, label) in enumerate(train_dataset.take(16)):\n",
        "  ax = plt.subplot(4,4,i+1)\n",
        "  plt.imshow(image)\n",
        "  plt.title(dataset_info.features['label'].int2str(label))\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "PVYzsIGzHqnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "In CNN models, images are often resized to a specific size like (224, 224, 3) for the following reasons:\n",
        "\n",
        "- Consistency: CNNs require all input images to have the same dimensions, so resizing standardizes the input.\n",
        "\n",
        "- Pretrained Models: Many popular models (e.g., VGG, ResNet) are trained on ImageNet, which uses 224x224 images.\n",
        "\n",
        "- Efficiency: Keeping the image size fixed helps reduce computational cost while preserving important spatial information.\n",
        "- Channels: The third dimension (3) corresponds to RGB color channels."
      ],
      "metadata": {
        "id": "0X2y8xj-oCQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We first have to resize our images\n",
        "IMG_SIZE = 224\n",
        "def resize_rescale(image, label):\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))/255.0\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "r4sZBAF-Hq_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(resize_rescale)\n",
        "test_dataset = test_dataset.map(resize_rescale)\n",
        "val_dataset = val_dataset.map(resize_rescale)"
      ],
      "metadata": {
        "id": "BWiPwh4THq8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in train_dataset.take(1):\n",
        "  print(f\"image shape : {image.shape}\")\n",
        "  print(f\"label : {label}\")\n",
        "  print(image, label)"
      ],
      "metadata": {
        "id": "daGeUAVQo-DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now that we have rescaled and resized our images we shuffle the daaset and we begin constructing the neural network model\n",
        "train_dataset = train_dataset.shuffle(buffer_size=8, reshuffle_each_iteration = True).batch(batch_size=32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "_HimlzM0pit_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = val_dataset.shuffle(buffer_size=8, reshuffle_each_iteration = True).batch(batch_size=32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "1mPB82y_iID0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_dataset.shuffle(buffer_size=8, reshuffle_each_iteration = True).batch(batch_size=32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "M9VT3cLJiH_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Model Implementation\n",
        "\n",
        "Resources on how a CNN Model works\n",
        "\n",
        "- CNN Explainer : https://poloclub.github.io/cnn-explainer/\n",
        "- Convolutional Neural Networks (CNNs) explained : https://youtu.be/YRhxdVk_sIs?si=puUIKMWZIy-jqnPC\n",
        "- Convolution Intorduction : Collaborative filtering, embeddings, and more  https://course17.fast.ai/lessons/lesson4.html\n",
        "- We will be copying he architecture of the lenet CNN : https://youtu.be/PcGCpxstTCg?si=zV3Dd57ipjnepFCq\n",
        "\n",
        "Basically convolution in the network occurs between a randomly initilized tensor of shape that we set and our input. We take the dot product of that and repeat the process for each combination of initialized tensors of that shape\n",
        "\n",
        "The dot product (also known as the scalar product) of two matrices is a way to multiply corresponding elements of two arrays (vectors or matrices) and then sum the results.\n",
        "\n",
        "In the context of matrices, the dot product is commonly used in matrix multiplication, particularly for multiplying rows by columns to generate elements of the result matrix.\n"
      ],
      "metadata": {
        "id": "TT-LeS7NqKet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, InputLayer, Conv2D, Flatten, BatchNormalization, MaxPool2D\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    InputLayer(input_shape = (IMG_SIZE,IMG_SIZE,3)),\n",
        "    #1st convolution layer and pool layer\n",
        "    tf.keras.layers.Conv2D(\n",
        "    filters =6,\n",
        "    kernel_size =3,\n",
        "    strides=1,\n",
        "    padding='valid',\n",
        "    activation = 'relu'),\n",
        "    BatchNormalization(),\n",
        "   tf.keras.layers.MaxPool2D(\n",
        "    pool_size=2,\n",
        "    strides=2,\n",
        "),\n",
        "    #2nd convolution layer and pool layer\n",
        "    tf.keras.layers.Conv2D(\n",
        "    filters =6,\n",
        "    kernel_size =3,\n",
        "    strides=1,\n",
        "    padding='valid',\n",
        "    activation = 'relu'),\n",
        "    BatchNormalization(),\n",
        "   tf.keras.layers.MaxPool2D(\n",
        "    pool_size=2,\n",
        "    strides=2,\n",
        "),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(10, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(1, activation='sigmoid'),])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xgiNd7gHqOvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason the activation functions in the hidden layers were changed from sigmoid to ReLU (Rectified Linear Unit) while keeping the last layer's activation function as sigmoid is based on the specific roles and properties of these activation functions in neural networks:\n",
        "\n",
        "# Hidden Layers with ReLU:\n",
        "ReLU is commonly used in hidden layers because it addresses some key problems that arise with the sigmoid activation:\n",
        "- Avoiding Vanishing Gradients: Sigmoid functions can cause vanishing gradients, where gradients become very small during backpropagation, leading to slow or stalled learning. ReLU avoids this by keeping the gradient large for positive values.\n",
        "- Better Performance: ReLU is computationally simple and more efficient than sigmoid for deeper networks because it introduces non-linearity while maintaining positive outputs for positive inputs and keeping zero for negative inputs. This helps the model learn complex patterns effectively.\n",
        "- Faster Convergence: ReLU tends to result in faster training and more efficient learning because it doesn't saturate like sigmoid does.\n",
        "\n",
        "# Final Layer with Sigmoid:\n",
        "Sigmoid is still used in the last layer because this layer is responsible for outputting a probability or binary classification result:\n",
        "- Output Between 0 and 1: Sigmoid maps its input to a value between 0 and 1, making it ideal for binary classification tasks. Since the modelâ€™s output is a single value (Dense(1)), it needs to represent the probability of one class versus another.\n",
        "- Binary Classification: In your case, the last layer produces a single output, and with the sigmoid activation, this value represents the probability that the input belongs to one class (e.g., 1) or the other class (e.g., 0).\n",
        "\n",
        "# Summary:\n",
        "ReLU is used in the hidden layers because it helps prevent vanishing gradients, improves efficiency, and leads to faster convergence in deeper networks.\n",
        "Sigmoid is kept in the final layer because it is well-suited for binary classification problems, where you want an output between 0 and 1 to represent a probability."
      ],
      "metadata": {
        "id": "HpJ6eiYMguWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set up loss and optimizers\n",
        "#since we are working on a binary classification problem we will use BinaryCrossEntropyLoss\n",
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "optim = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "#metrics = ['accuracy']"
      ],
      "metadata": {
        "id": "owH4YumwqPYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optim, loss=loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YcVKi6iHqPV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim.learning_rate"
      ],
      "metadata": {
        "id": "mvPt0rcVeHWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of the first element in the dataset\n",
        "for data, label in train_dataset:\n",
        "    print(\"Data shape:\", data.shape)\n",
        "    print(\"Label shape:\", label.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "fCc4FmkyTiN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "During training and evaluation we will need to be wary that our model does not suffer from :\n",
        "- overfitting\n",
        "- underfitting\n",
        "\n",
        "This source explains both issues and how to resolve them in detail : https://www.youtube.com/watch?v=W-0-u6XVbE4\n",
        "\n",
        "Additional Resources : https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/\n",
        "\n",
        "For this particular model through expirementation what has been found to produce good results in terms of the metrics that we used is :  \n",
        "- the dataset records to around 2000\n",
        "- reduce the kernels of our CNN model to 3\n",
        "- reduce filters of our CNN model to 6 in both layers. Both of these adjustments are made to reduce the compelxity of the model\n",
        "- add ```BatchNormalization()``` to normalize the input (for more on how normalization works see https://github.com/AntonisGantzos/Tensorflow-ML_Projects/blob/main/Second_hand_car_prices_prediction_(TensorFlow_Regression_project).ipynb)\n",
        "- adjust the optimizer's learning rate to about 0.01\n",
        "- set the epochs that the model will train to around 15"
      ],
      "metadata": {
        "id": "Q6XjZABKzhoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset,validation_data=val_dataset, epochs=15, verbose = 1)"
      ],
      "metadata": {
        "id": "1Mmm3PUMR2ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the loss function\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rCr69AMQlZCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')"
      ],
      "metadata": {
        "id": "Xnfv3RI4lcR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "Rjo6ezBvn_HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "Y7l56O1DoA60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parasite_or_not(x):\n",
        "  if x < 0.5:\n",
        "    return \"P\"\n",
        "  else:\n",
        "    return \"U\""
      ],
      "metadata": {
        "id": "bPF0QrNxuukM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a probability closer to 0 means that our input image is most likely that of an infected patient while a probability closer to 1 means it is probably an image of an uninfected\n",
        "parasite_or_not(model.predict(test_dataset.take(1))[0][0])"
      ],
      "metadata": {
        "id": "eKlRYp9TpHuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (image, label) in enumerate(test_dataset.take(9)):\n",
        "  ax = plt.subplot(3,3,i+1)\n",
        "  plt.imshow(image[0])\n",
        "  plt.title(f\"{parasite_or_not(model.predict(image)[0][0])}  : {parasite_or_not(label.numpy()[0])}\")\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "SHTvMqGivT1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Load the Model"
      ],
      "metadata": {
        "id": "RF9Wu7Fr1RJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "b3O83B-4B9Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path where you want to save the model on Google Drive\n",
        "model_save_path = '/content/drive/My Drive/model_name.h5'\n",
        "\n",
        "# Save the entire model (weights + configuration)\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "id": "s43FJQp4CW7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model from Google Drive\n",
        "model_load_path = '/content/drive/My Drive/model_name.h5'\n",
        "loaded_model = tf.keras.models.load_model(model_load_path)\n",
        "print(f\"Model {loaded_model} loaded successfully.\")"
      ],
      "metadata": {
        "id": "-skukPm7Ct6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Functional API\n",
        "So far we have only been using Sequential API for he creation our models. This works fine in classification problems but for models with more than one input and output (which are used in types of problems like finding the position of the parasitic cell in a given image for example), Functional API is our best approach\n",
        "\n",
        "It also allows us to create more complex models that provide better results. A good example of that architecure is ResNet (https://www.geeksforgeeks.org/residual-networks-resnet-deep-learning/)\n",
        "\n",
        "Additional Resources\n",
        "- ResNet (actually) explained in under 10 minutes :\n",
        "https://www.youtube.com/watch?v=o_3mboe1jYI"
      ],
      "metadata": {
        "id": "mQIW5QMADls_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Model, Input, Layer\n",
        "from keras.layers import Dense, InputLayer, Conv2D, Flatten, BatchNormalization, MaxPool2D\n",
        "class Feature_Extractor(keras.layers.Layer):\n",
        "  def __init__(self, filters, kernel_size, strides, padding, activation, pool_size,):\n",
        "    super(Feature_Extractor, self).__init__()\n",
        "\n",
        "    self.conv_1 = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding, activation = activation)\n",
        "    self.batch_1 = BatchNormalization()\n",
        "    self.pool_1 = MaxPool2D (pool_size = pool_size, strides= 2*strides)\n",
        "\n",
        "    self.conv_2 = Conv2D(filters = filters*2, kernel_size = kernel_size, strides = strides, padding = padding, activation = activation)\n",
        "    self.batch_2 = BatchNormalization()\n",
        "    self.pool_2 = MaxPool2D (pool_size = pool_size, strides= 2*strides)\n",
        "\n",
        "    self.conv_3 = Conv2D(filters=filters*4, kernel_size=kernel_size, strides=strides, padding=padding, activation=activation)\n",
        "    self.batch_3 = BatchNormalization()\n",
        "    self.pool_3 = MaxPool2D(pool_size=pool_size, strides=2*strides)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "      # No additional weights to build manually in this case, as all layers are standard layers\n",
        "      # But you can add custom weights if needed.\n",
        "      super(Feature_Extractor, self).build(input_shape)  # This ensures the layer is marked as built.\n",
        "\n",
        "  def call(self, x):\n",
        "\n",
        "    #print(x.shape)\n",
        "    x = self.conv_1(x)\n",
        "    #print(x.shape)\n",
        "    x = self.batch_1(x)\n",
        "    #print(x.shape)\n",
        "    x = self.pool_1(x)\n",
        "    #print(x.shape)\n",
        "\n",
        "    x = self.conv_2(x)\n",
        "    #print(x.shape)\n",
        "    x = self.batch_2(x)\n",
        "    #print(x.shape)\n",
        "    x = self.pool_2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "feature_extractor = Feature_Extractor(8, 3, 1, \"valid\", \"relu\", 2)\n",
        "#feature_extractor.build(input_shape=(1, 224, 224, 3))  # Specify the input shape (batch size, height, width, channels)\n",
        "x = tf.zeros([1, 224, 224, 3])  # A sample input\n",
        "feature_extractor(x)\n"
      ],
      "metadata": {
        "id": "EB-qlRhOL06N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Model, Input\n",
        "from keras.layers import Dense, InputLayer, Conv2D, Flatten, BatchNormalization, MaxPool2D\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "functional_api_input = Input(shape= (IMG_SIZE,IMG_SIZE,3), name = \"Input Image\")\n",
        "\n",
        "class Model_v_2(keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super(Model_v_2, self).__init__()\n",
        "\n",
        "    self.feature_extractor = Feature_Extractor(8, 3, 1, \"valid\", \"relu\", 2)\n",
        "\n",
        "    self.flatten = Flatten()\n",
        "\n",
        "    self.dense_1 = Dense(100, activation = \"relu\")\n",
        "    self.batch_1 = BatchNormalization()\n",
        "\n",
        "    self.dense_2 = Dense(10, activation = \"relu\")\n",
        "    self.batch_2 = BatchNormalization()\n",
        "\n",
        "    self.dense_3 = Dense(1, activation = \"sigmoid\")\n",
        "\n",
        "  def call(self, x):\n",
        "    #print(x.shape)\n",
        "    x = self.feature_extractor(x)\n",
        "    #print(x.shape)\n",
        "    x = self.flatten(x)\n",
        "    #print(x.shape)\n",
        "    x = self.dense_1(x)\n",
        "    #print(x.shape)\n",
        "    x = self.batch_1(x)\n",
        "    #print(x.shape)\n",
        "    x = self.dense_2(x)\n",
        "    #print(x.shape)\n",
        "    x = self.batch_2(x)\n",
        "    #print(x.shape)\n",
        "    x = self.dense_3(x)\n",
        "    #print(x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "model_v_2 = Model_v_2()\n",
        "model_v_2(tf.zeros([1, 224, 224, 3]))  # Specify the input shape (batch size, height, width, channels)\n",
        "model_v_2.summary()"
      ],
      "metadata": {
        "id": "yPrxVNrXmQ7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss=loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GLMKwrFJtXFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_v_2.fit(train_dataset,validation_data=val_dataset, epochs=15, verbose = 1)"
      ],
      "metadata": {
        "id": "Z9q83R6GtZ-Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}